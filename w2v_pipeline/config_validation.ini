target_columns = string_list

_PARALLEL = boolean
_FORCE = boolean

[import_data]

    input_data_directories = string_list
    output_data_directory  = string(default="data_sql")
    
    data_type = string(default="csv")
    output_table = string(default="original")

[phrase_identification]

    f_abbreviations = string(default="abbreviations.sqlite")
    output_data_directory = string(default="data_document_scores")
    output_table = string(default="abbreviations")

[parse]

    output_table = string(default="parsed")
    output_data_directory = string(default="data_parsed")
    
    pipeline = string_list

    [[replace_from_dictionary]]
        input_data_directory = string(default="w2v_pipeline/preprocessing/dictionaries")
        f_dict = string(default="MeSH_two_word_lexicon.csv")
    
    [[replace_phrases]]
        input_data_directory =  string(default="data_document_scores")
        f_abbreviations =  string(default="abbreviations.sqlite")

    [[pos_tokenizer]]
        POS_blacklist = string_list

[embedding]

    input_data_directory  = string(default="data_parsed")
    output_data_directory = string(default="data_embeddings")
    embedding_commands    = string_list

    [[w2v_embedding]]      
        f_db = string(default="w2v.gensim")
      	skip_gram = 0
      	hierarchical_softmax = 0
        epoch_n = 80
        window = 5
        negative = 5
        sample = 1e-5
        size = 300
        min_count = 10

    [[d2v_embedding]]      
        f_db = string(default="d2v.gensim")
        epoch_n = 80
        window = 5
        negative = 5
        sample = 1e-5
        size = 300
        min_count = 10

[score]

    output_data_directory = string(default="data_document_scores")
    mapreduce_commands    = string_list
    globaldata_commands   = string_list
  
    compute_reduced_representation = boolean

    [[reduced_representation]]
        n_components = integer(25)
  
    [[term_frequency]]
        f_db = string(default="TF.sqlite")
        #command_whitelist = string_list
    [[term_document_frequency]]   
        f_db = string(default="TF.sqlite")
    [[document_log_probability]]
      	f_partition_function = string(default="w2v_partition_function.h5")
      	f_db = string(default="log_prob.h5")
      	intra_document_cutoff = 0.10

    [[score_Z_weighted]]
      	kT = 1.5
      	threshold = 0.0

    [[score_simple]]
    [[score_unique]]
    [[score_simple_TF]]
    [[score_unique_TF]]
    [[score_locality_hash]]
        locality_n_bits = 12
        locality_alpha  = 0.00

    [[document_scores]]
        f_db  = string(default="document_scores.h5"

[predict]
    categorical_columns = string_list

    n_estimators = 200
    cross_validation_folds = 12
    
    meta_methods = string_list

    use_SMOTE = boolean(default=False)
    use_reduced = boolean(default=False)
    use_meta = boolean(default=False)


[metacluster]

    score_method = string
    score_column = string

    subcluster_m = 1000
    subcluster_kn = 15
    
    subcluster_pcut = 0.80
    subcluster_repeats = 1

    output_data_directory = string(default="data_clustering")
    f_centroids = string(default="meta_cluster_centroids.h5")


[cluster]

    predict_target_directory = string(default="data_sql/")
    
    score_method = string
    score_column = string

    output_data_directory = string(default="data_clustering")
    f_cluster = string(default="clustering.h5")
    
    clustering_commands = string_list
    command_whitelist = string_list

    [[spectral_clustering]]
        n_clusters = 4

    [[hdbscan_clustering]]
        min_cluster_size = 30
    
