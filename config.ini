#target_columns  = abstract,specificAims,
target_columns  = title_abstract,specific_aims

#_PARALLEL = False
_PARALLEL = True
_FORCE = False

[import_data]

    input_data_directories = datasets,
    output_data_directory  = data_sql
    
    data_type = csv
    output_table = original

[embedding]

    input_data_directory  = data_parsed
    output_data_directory = data_embeddings
    embedding_commands    = w2v_embedding,
    #embedding_commands    = w2v_embedding, d2v_embedding

    [[w2v_embedding]]      
        f_db = w2v.gensim
        epoch_n = 40
        window = 5
        negative = 5
        sample = 1e-5
        size = 300
        min_count = 10

    [[d2v_embedding]]      
        f_db = d2v.gensim
        epoch_n = 80
        window = 5
        negative = 5
        sample = 1e-5
        size = 300
        min_count = 10

[score]

    output_data_directory = data_document_scores

    #mapreduce_commands    = term_document_frequency, term_frequency
    mapreduce_commands    = 
    globaldata_commands   = document_scores,
   
    [[term_frequency]]
        f_db = TF.sqlite
        command_whitelist =

    [[term_document_frequency]]   
        f_db = TF.sqlite

    [[document_scores]]
        methods = simple_TF, unique_TF, simple, unique
        f_db  = document_scores.h5

[phrase_identification]

    f_abbreviations = abbreviations.sqlite
    output_data_directory = data_document_scores
    output_table = abbreviations

[parse]

    output_table = parsed
    output_data_directory = data_parsed
    
    pipeline = replace_phrases, remove_parenthesis, token_replacement, decaps_text, pos_tokenizer

    [[replace_phrases]]
        input_data_directory = data_document_scores
        f_abbreviations = abbreviations.sqlite

    [[pos_tokenizer]]
        POS_blacklist = connector, cardinal, pronoun, symbol, punctuation, modal_verb, adverb, w_word, verbs
