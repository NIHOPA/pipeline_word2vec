target_columns  = abstract,

_PARALLEL = True
_FORCE = True

[import_data]

    input_data_directories = datasets,
    output_data_directory  = data_sql
    
    data_type = csv
    output_table = original

[predict]
    
    f_db_scores  = collated/document_scores.h5
    predict_target_directory = data_sql/
    categorical_columns = journal,

    n_estimators = 200
    cross_validation_folds = 10

[train]

    mapreduce_commands    = term_frequency,
    globaldata_commands   = w2v_embedding, document_scores,
    input_data_directory  = data_parsed

    [[term_frequency]]
        f_db = collated/TF.sqlite
        command_whitelist = bio,

    [[w2v_embedding]]      
        f_db = collated/w2v.h5
        epoch_n = 2
        window = 5
        negative = 5
        sample = 1e-5
        size = 200
        min_count = 10

    [[document_scores]]
        methods = simple, unique
        f_w2v = collated/w2v.h5
        f_db  = collated/document_scores.h5
        command_whitelist = bio,    
    

[phrase_identification]

    f_abbreviations = abbreviations.sqlite
    output_data_directory = collated
    output_table = abbreviations

[parse]

    output_table = parsed
    output_data_directory = data_parsed
    
    pipeline = replace_phrases, remove_parenthesis, token_replacement, decaps_text, pos_tokenizer

    [[replace_phrases]]
        input_data_directory = collated
        f_abbreviations = abbreviations.sqlite

    [[pos_tokenizer]]
        POS_blacklist = connector, cardinal, pronoun,  adverb, symbol, verb, punctuation, modal_verb, w_word